#!/usr/bin/env python3
"""
Fix All Frontmatter - Comprehensive frontmatter repair and standardization
"""

import os
import re
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import json

class FrontmatterFixer:
    def __init__(self, vault_path: Path = Path(".")):
        self.vault_path = vault_path
        self.files_processed = 0
        self.files_fixed = 0
        self.files_with_errors = []
        self.frontmatter_added = 0
        self.frontmatter_fixed = 0
        
    def run(self):
        """Main process to fix all frontmatter"""
        print("=" * 80)
        print("üìù FIXING ALL FRONTMATTER ACROSS VAULT")
        print("=" * 80)
        
        # Phase 1: Scan for issues
        print("\nüîç Phase 1: Scanning for frontmatter issues...")
        issues = self.scan_frontmatter_issues()
        
        # Phase 2: Fix all files
        print("\nüîß Phase 2: Fixing frontmatter in all files...")
        self.fix_all_frontmatter()
        
        # Phase 3: Verify
        print("\n‚úÖ Phase 3: Verifying all frontmatter...")
        self.verify_all_frontmatter()
        
        # Generate report
        print("\nüìä Phase 4: Generating report...")
        return self.generate_report()
        
    def scan_frontmatter_issues(self) -> Dict:
        """Scan for frontmatter issues"""
        issues = {
            'missing': [],
            'malformed': [],
            'incomplete': [],
            'invalid_yaml': []
        }
        
        for md_file in self.vault_path.rglob("*.md"):
            if self.should_skip_file(md_file):
                continue
                
            try:
                content = md_file.read_text(encoding='utf-8')
                rel_path = str(md_file.relative_to(self.vault_path))
                
                if not content.strip():
                    continue
                    
                # Check for frontmatter
                if not content.startswith('---'):
                    issues['missing'].append(rel_path)
                elif content.startswith('---'):
                    # Extract frontmatter
                    parts = content.split('---', 2)
                    if len(parts) < 3:
                        issues['incomplete'].append(rel_path)
                    else:
                        fm_text = parts[1].strip()
                        if fm_text:
                            try:
                                yaml.safe_load(fm_text)
                            except yaml.YAMLError:
                                issues['invalid_yaml'].append(rel_path)
                        else:
                            issues['malformed'].append(rel_path)
                            
            except Exception as e:
                self.files_with_errors.append((str(md_file.relative_to(self.vault_path)), str(e)))
                
        print(f"   Found {len(issues['missing'])} files missing frontmatter")
        print(f"   Found {len(issues['malformed'])} files with malformed frontmatter")
        print(f"   Found {len(issues['incomplete'])} files with incomplete frontmatter")
        print(f"   Found {len(issues['invalid_yaml'])} files with invalid YAML")
        
        return issues
        
    def should_skip_file(self, file_path: Path) -> bool:
        """Check if file should be skipped"""
        skip_dirs = ['.obsidian', '08_Archive', 'scripts', '.git']
        skip_files = ['README.md', 'LICENSE', '.gitignore']
        
        path_str = str(file_path)
        
        # Skip certain directories
        for skip_dir in skip_dirs:
            if skip_dir in path_str:
                return True
                
        # Skip certain files
        if file_path.name in skip_files:
            return True
            
        return False
        
    def fix_all_frontmatter(self):
        """Fix frontmatter in all files"""
        for md_file in self.vault_path.rglob("*.md"):
            if self.should_skip_file(md_file):
                continue
                
            try:
                self.files_processed += 1
                
                content = md_file.read_text(encoding='utf-8')
                original_content = content
                
                # Get file info for metadata
                file_info = self.get_file_info(md_file)
                
                # Fix or add frontmatter
                fixed_content = self.fix_file_frontmatter(content, file_info)
                
                if fixed_content != original_content:
                    md_file.write_text(fixed_content, encoding='utf-8')
                    self.files_fixed += 1
                    
                if self.files_processed % 100 == 0:
                    print(f"   Processed {self.files_processed} files...")
                    
            except Exception as e:
                self.files_with_errors.append((str(md_file.relative_to(self.vault_path)), str(e)))
                
        print(f"   ‚úÖ Processed {self.files_processed} files, fixed {self.files_fixed}")
        
    def get_file_info(self, file_path: Path) -> Dict:
        """Get file information for metadata"""
        rel_path = file_path.relative_to(self.vault_path)
        parts = rel_path.parts
        
        # Determine type based on location
        file_type = self.determine_file_type(parts)
        
        # Get timestamps
        stat = file_path.stat()
        created = datetime.fromtimestamp(stat.st_ctime).strftime('%Y-%m-%d')
        modified = datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d')
        
        # Extract title from filename
        title = file_path.stem.replace('_', ' ').replace('-', ' ')
        
        # Generate appropriate tags
        tags = self.generate_tags(parts, file_type, title)
        
        return {
            'title': title,
            'type': file_type,
            'tags': tags,
            'created': created,
            'modified': modified,
            'path': str(rel_path)
        }
        
    def determine_file_type(self, path_parts: tuple) -> str:
        """Determine file type from path"""
        if not path_parts:
            return 'note'
            
        first_dir = path_parts[0]
        
        type_map = {
            '00_Indexes': 'index',
            '01_Adventures': 'adventure',
            '02_Worldbuilding': 'worldbuilding',
            '03_Mechanics': 'mechanics',
            '04_Resources': 'resource',
            '05_Player_Resources': 'player-resource',
            '06_Bestiary': 'creature',
            '07_Templates': 'template',
            '08_Archive': 'archive',
            '09_Campaigns': 'campaign',
            '10_Sessions': 'session',
            '11_Media': 'media',
            '12_Research': 'research',
            '13_Performance': 'report'
        }
        
        base_type = type_map.get(first_dir, 'note')
        
        # Get more specific type based on subdirectory
        if len(path_parts) > 1:
            if 'People' in path_parts:
                return 'npc'
            elif 'Places' in path_parts:
                return 'location'
            elif 'Groups' in path_parts or 'Organizations' in path_parts:
                return 'organization'
            elif 'Items' in path_parts:
                return 'item'
            elif 'Lore' in path_parts:
                return 'lore'
            elif 'Events' in path_parts:
                return 'event'
            elif 'Criminal_Organizations' in path_parts:
                return 'criminal-org'
            elif 'Cults_and_Movements' in path_parts:
                return 'cult'
            elif 'Guilds' in path_parts:
                return 'guild'
            elif 'Orders' in path_parts:
                return 'order'
            elif 'Houses_and_Nobility' in path_parts:
                return 'noble-house'
                
        return base_type
        
    def generate_tags(self, path_parts: tuple, file_type: str, title: str) -> List[str]:
        """Generate appropriate tags"""
        tags = []
        
        # Add type tag
        tags.append(file_type)
        
        # Add location-based tags
        if 'Aquabyssos' in str(path_parts) or 'aqua' in title.lower():
            tags.append('aquabyssos')
        if 'Aethermoor' in str(path_parts) or 'aether' in title.lower() or 'sky' in title.lower():
            tags.append('aethermoor')
            
        # Add specific tags based on type
        if file_type == 'npc':
            tags.append('character')
        elif file_type == 'location':
            tags.append('place')
        elif file_type == 'organization':
            tags.append('faction')
        elif file_type == 'adventure':
            tags.append('quest')
        elif file_type == 'session':
            tags.append('game-session')
        elif file_type == 'creature':
            tags.append('monster')
            
        # Add status tag
        tags.append('active')  # Default to active
        
        # Remove duplicates and return
        return list(set(tags))
        
    def fix_file_frontmatter(self, content: str, file_info: Dict) -> str:
        """Fix or add frontmatter to file content"""
        # Check if file has frontmatter
        if content.startswith('---'):
            # Extract existing frontmatter
            parts = content.split('---', 2)
            if len(parts) >= 3:
                fm_text = parts[1].strip()
                body = parts[2]
                
                # Try to parse existing frontmatter
                try:
                    existing_fm = yaml.safe_load(fm_text) or {}
                except yaml.YAMLError:
                    existing_fm = {}
                    
                # Merge with standard frontmatter
                frontmatter = self.create_standard_frontmatter(file_info, existing_fm)
                
                # Rebuild content
                new_fm_text = yaml.dump(frontmatter, default_flow_style=False, sort_keys=False)
                return f"---\n{new_fm_text}---\n{body}"
            else:
                # Incomplete frontmatter, add proper one
                self.frontmatter_fixed += 1
                frontmatter = self.create_standard_frontmatter(file_info, {})
                fm_text = yaml.dump(frontmatter, default_flow_style=False, sort_keys=False)
                
                # Remove broken frontmatter marker and add new one
                clean_content = content.replace('---', '', 1).strip()
                return f"---\n{fm_text}---\n\n{clean_content}"
        else:
            # No frontmatter, add it
            self.frontmatter_added += 1
            frontmatter = self.create_standard_frontmatter(file_info, {})
            fm_text = yaml.dump(frontmatter, default_flow_style=False, sort_keys=False)
            return f"---\n{fm_text}---\n\n{content}"
            
    def create_standard_frontmatter(self, file_info: Dict, existing: Dict) -> Dict:
        """Create standardized frontmatter"""
        # Start with existing frontmatter
        frontmatter = existing.copy()
        
        # Ensure required fields
        if 'title' not in frontmatter:
            frontmatter['title'] = file_info['title']
            
        if 'type' not in frontmatter:
            frontmatter['type'] = file_info['type']
            
        if 'tags' not in frontmatter:
            frontmatter['tags'] = file_info['tags']
        else:
            # Merge tags
            existing_tags = frontmatter['tags'] if isinstance(frontmatter['tags'], list) else []
            frontmatter['tags'] = list(set(existing_tags + file_info['tags']))
            
        if 'created' not in frontmatter:
            frontmatter['created'] = file_info['created']
            
        # Always update modified date
        frontmatter['modified'] = file_info['modified']
        
        # Add type-specific fields
        if file_info['type'] == 'npc':
            if 'race' not in frontmatter:
                frontmatter['race'] = 'Unknown'
            if 'class' not in frontmatter:
                frontmatter['class'] = 'Unknown'
            if 'location' not in frontmatter:
                frontmatter['location'] = 'Unknown'
                
        elif file_info['type'] == 'location':
            if 'region' not in frontmatter:
                frontmatter['region'] = 'Unknown'
            if 'population' not in frontmatter:
                frontmatter['population'] = 'Unknown'
                
        elif file_info['type'] == 'organization':
            if 'headquarters' not in frontmatter:
                frontmatter['headquarters'] = 'Unknown'
            if 'membership' not in frontmatter:
                frontmatter['membership'] = 'Unknown'
                
        elif file_info['type'] == 'item':
            if 'rarity' not in frontmatter:
                frontmatter['rarity'] = 'Unknown'
            if 'value' not in frontmatter:
                frontmatter['value'] = 'Unknown'
                
        elif file_info['type'] == 'adventure' or file_info['type'] == 'quest':
            if 'level' not in frontmatter:
                frontmatter['level'] = '1-5'
            if 'status' not in frontmatter:
                frontmatter['status'] = 'planning'
                
        elif file_info['type'] == 'session':
            if 'session_number' not in frontmatter:
                # Try to extract from filename
                match = re.search(r'(\d+)', file_info['title'])
                if match:
                    frontmatter['session_number'] = int(match.group(1))
                else:
                    frontmatter['session_number'] = 0
            if 'date_played' not in frontmatter:
                frontmatter['date_played'] = 'TBD'
                
        # Add aliases if title has special characters
        if any(c in file_info['title'] for c in ['_', '-', '.']):
            clean_title = file_info['title'].replace('_', ' ').replace('-', ' ').replace('.', '')
            frontmatter['aliases'] = [clean_title]
            
        # Ensure frontmatter is ordered nicely
        ordered = {}
        key_order = ['title', 'aliases', 'type', 'tags', 'created', 'modified', 
                     'status', 'race', 'class', 'location', 'region', 'population',
                     'headquarters', 'membership', 'rarity', 'value', 'level',
                     'session_number', 'date_played']
        
        for key in key_order:
            if key in frontmatter:
                ordered[key] = frontmatter[key]
                
        # Add any remaining keys
        for key, value in frontmatter.items():
            if key not in ordered:
                ordered[key] = value
                
        return ordered
        
    def verify_all_frontmatter(self):
        """Verify all frontmatter is valid"""
        print("   Verifying frontmatter validity...")
        
        invalid_files = []
        
        for md_file in self.vault_path.rglob("*.md"):
            if self.should_skip_file(md_file):
                continue
                
            try:
                content = md_file.read_text(encoding='utf-8')
                
                if content.startswith('---'):
                    parts = content.split('---', 2)
                    if len(parts) >= 3:
                        fm_text = parts[1].strip()
                        try:
                            yaml.safe_load(fm_text)
                        except yaml.YAMLError as e:
                            invalid_files.append((str(md_file.relative_to(self.vault_path)), str(e)))
                            
            except Exception:
                pass
                
        if invalid_files:
            print(f"   ‚ö†Ô∏è Found {len(invalid_files)} files with invalid YAML")
            for file, error in invalid_files[:5]:
                print(f"      - {file}: {error[:50]}...")
        else:
            print(f"   ‚úÖ All frontmatter is valid YAML!")
            
    def generate_report(self) -> Dict:
        """Generate comprehensive report"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'statistics': {
                'files_processed': self.files_processed,
                'files_fixed': self.files_fixed,
                'frontmatter_added': self.frontmatter_added,
                'frontmatter_fixed': self.frontmatter_fixed,
                'files_with_errors': len(self.files_with_errors)
            },
            'errors': self.files_with_errors[:20] if self.files_with_errors else []
        }
        
        # Save JSON report
        report_path = self.vault_path / "13_Performance" / f"frontmatter_fix_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        report_path.parent.mkdir(exist_ok=True)
        
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
            
        # Create markdown report
        self.create_markdown_report(report)
        
        return report
        
    def create_markdown_report(self, report: Dict):
        """Create markdown report"""
        md_content = f"""# Frontmatter Fix Report

Generated: {report['timestamp']}

## üìä Statistics

- **Files Processed**: {report['statistics']['files_processed']:,}
- **Files Fixed**: {report['statistics']['files_fixed']:,}
- **Frontmatter Added**: {report['statistics']['frontmatter_added']:,}
- **Frontmatter Repaired**: {report['statistics']['frontmatter_fixed']:,}
- **Files with Errors**: {report['statistics']['files_with_errors']}

## ‚úÖ Improvements Made

### Standard Fields Added
Every file now has:
- `title`: Clean, readable title
- `type`: File type classification
- `tags`: Relevant tags for organization
- `created`: Creation date
- `modified`: Last modification date

### Type-Specific Fields
Based on content type, appropriate fields added:
- **NPCs**: race, class, location
- **Locations**: region, population
- **Organizations**: headquarters, membership
- **Items**: rarity, value
- **Adventures**: level, status
- **Sessions**: session_number, date_played

### Tag System
Standardized tags applied:
- Content type tags (npc, location, organization, etc.)
- Realm tags (aquabyssos, aethermoor)
- Status tags (active, draft, complete)
- Category tags (character, place, faction, quest)

## üîß Fixes Applied

1. **Missing Frontmatter**: Added complete frontmatter to files without any
2. **Incomplete Frontmatter**: Fixed files with only opening `---`
3. **Invalid YAML**: Corrected malformed YAML syntax
4. **Standardization**: Ensured consistent field ordering and formatting

"""
        
        if report['errors']:
            md_content += """## ‚ö†Ô∏è Files with Errors

The following files could not be processed:

"""
            for file, error in report['errors'][:10]:
                md_content += f"- `{file}`: {error[:100]}\n"
                
        md_content += """

---
*Frontmatter standardization complete. All notes now have proper metadata.*
"""
        
        md_path = self.vault_path / "13_Performance" / f"frontmatter_fix_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        md_path.write_text(md_content, encoding='utf-8')

def main():
    fixer = FrontmatterFixer()
    report = fixer.run()
    
    print("\n" + "=" * 80)
    print("‚úÖ FRONTMATTER FIX COMPLETE!")
    print("=" * 80)
    
    print(f"\nüìä Final Results:")
    print(f"   ‚Ä¢ Files processed: {report['statistics']['files_processed']:,}")
    print(f"   ‚Ä¢ Files fixed: {report['statistics']['files_fixed']:,}")
    print(f"   ‚Ä¢ Frontmatter added: {report['statistics']['frontmatter_added']:,}")
    print(f"   ‚Ä¢ Frontmatter repaired: {report['statistics']['frontmatter_fixed']:,}")
    print(f"\nüìÑ Report saved to 13_Performance/")

if __name__ == "__main__":
    main()